{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset version: 2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1158e73790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#!python3 -m pip install pytorch_lightning\n",
    "#!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from model import LSTM_Model\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from torch import save\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Validation set\n",
      "data/bcm//validation/0.npy\n",
      "data/bcm//validation/1.npy\n",
      "data/bcm//validation/2.npy\n",
      "data/bcm//validation/3.npy\n",
      "data/bcm//validation/4.npy\n",
      "Training set\n",
      "data/bcm//train/0.npy\n",
      "data/bcm//train/1.npy\n",
      "data/bcm//train/2.npy\n",
      "data/bcm//train/3.npy\n",
      "data/bcm//train/4.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | lstm         | LSTM             | 42.0 K\n",
      "1 | fc           | Linear           | 645   \n",
      "2 | flatten      | Flatten          | 0     \n",
      "3 | output       | Sigmoid          | 0     \n",
      "4 | sm           | Softmax          | 0     \n",
      "5 | loss         | CrossEntropyLoss | 0     \n",
      "6 | accuracy     | Accuracy         | 0     \n",
      "7 | val_accuracy | Accuracy         | 0     \n",
      "--------------------------------------------------\n",
      "42.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.6 K    Total params\n",
      "0.171     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progress_bar': {'val_loss': 1.620288372039795}, 'log': {'val_loss': 1.620288372039795}, 'val_loss': 1.620288372039795}\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aron/.local/lib/python3.9/site-packages/pytorch_lightning/core/module.py:555: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=self.device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0385e4af184511ac38d36921937d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde33c986ad403e9f198e086f6bdfb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd40bdbec91240aeadb7f65db3d346a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progress_bar': {'val_loss': 1.432177186012268}, 'log': {'val_loss': 1.432177186012268}, 'val_loss': 1.432177186012268}\n",
      "Accuracy: 0.7923994064331055\n",
      "Accuracy: 0.7953887581825256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cecf89854704dd8bb6eed7e66f5b207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731e4b9425e849909f8a1fbe32ab443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progress_bar': {'val_loss': 1.4177210330963135}, 'log': {'val_loss': 1.4177210330963135}, 'val_loss': 1.4177210330963135}\n",
      "Accuracy: 0.9708523750305176\n",
      "Accuracy: 0.9875033497810364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3344edff193b4bbbac4e578b6278cfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progress_bar': {'val_loss': 1.4169402122497559}, 'log': {'val_loss': 1.4169402122497559}, 'val_loss': 1.4169402122497559}\n",
      "Accuracy: 0.9741328358650208\n",
      "Accuracy: 0.991460919380188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1222838d63b5467d888d486714131e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8114d420a94c9f8a232661fa5dadd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ce79481613477393d00cdbf726ea72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bc5a8a0c4c4596a3b4284592060ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f919514584f24341a4306c64c2596417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c12d6a6a2254184af85d50f8c40fc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be3ab8fbc744eb99751833f498c3f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aca54dda344e11b2e1edb434608aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d70d2b3f53f4ab2b41abf71c298f633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82c6a090b664299b6f9ec4efe2e67f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b369da9ce34211ac963483605d34d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a007281b96754c66a32c6cd950d94c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'progress_bar': {'val_loss': 1.4166594743728638}, 'log': {'val_loss': 1.4166594743728638}, 'val_loss': 1.4166594743728638}\n",
      "Accuracy: 0.9752442240715027\n",
      "Accuracy: 0.9982410669326782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f675d5d415444aa923041733ac507d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca7420b16974c42bc473428bdc82527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c313855e134bb1a91b98480c446ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354526e2b38b433f8b24cfd9e1507e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525202aa81d04a598931ded9c2e0b4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3af3573df4146bba743fc5808d36b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166f6c57510d497197ee2ee7ae73e0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9919c5ef7505443380721a2966d47477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #Check for cuda \n",
    "#device = 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "for stride in [0.1,0.5,1,2,3][3,2,1,0.5,0.1]:\n",
    "    model = LSTM_Model('data/bcm/', window_size = 3, stride = stride).to(device)\n",
    "\n",
    "    trainer = Trainer(max_epochs=100, min_epochs=1, auto_lr_find=False, auto_scale_batch_size=False,enable_checkpointing=False, accelerator=\"gpu\", devices = 1)\n",
    "\n",
    "    trainer.tune(model)\n",
    "\n",
    "    trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aron/.local/lib/python3.9/site-packages/torch/jit/_recursive.py:621: LightningDeprecationWarning: `LightningModule.use_amp` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.amp_backend`.\n",
      "  item = getattr(mod, name, None)\n",
      "/home/aron/.local/lib/python3.9/site-packages/torch/jit/_recursive.py:708: LightningDeprecationWarning: `LightningModule.use_amp` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.amp_backend`.\n",
      "  item = getattr(nn_module, name, None)\n",
      "/home/aron/.local/lib/python3.9/site-packages/torch/jit/_recursive.py:508: LightningDeprecationWarning: `LightningModule.use_amp` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.amp_backend`.\n",
      "  item = getattr(nn_module, name, None)\n",
      "/home/aron/.local/lib/python3.9/site-packages/torch/jit/_recursive.py:591: LightningDeprecationWarning: `LightningModule.use_amp` was deprecated in v1.6 and will be removed in v1.8. Please use `Trainer.amp_backend`.\n",
      "  item = getattr(nn_module, name, None)\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model.state_dict(), \"trained_models/oct_6_3_sec_window\")\n",
    "\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(\"trained_models/oct_6_3_sec_window\") # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93, 16])\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "482\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from BCM_dataset_v2 import bcmDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#model.eval()\n",
    "\n",
    "model_loaded = torch.jit.load('trained_models/2')\n",
    "model_loaded.eval()\n",
    "\n",
    "ds = bcmDataset('data/bcm/4.npy', class_id = 4, window_size = 3, stride = 3, MFCC_stride = 0.032)\n",
    "\n",
    "\n",
    "t = 0\n",
    "f = 0\n",
    "\n",
    "\n",
    "print(ds[2][0].shape)\n",
    "for i in range(0, len(ds)):\n",
    "    # Remeber to insert empty/None dimension to test a single datapoint!!!!!!!!!\n",
    "    test = ds[i][0]\n",
    "    test = test[None,:,:]\n",
    "    print(model_loaded(test).argmax())\n",
    "    if model_loaded(test).argmax() == 4:\n",
    "        t += 1\n",
    "    else:\n",
    "        f += 1\n",
    "\n",
    "print(t)\n",
    "print(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
