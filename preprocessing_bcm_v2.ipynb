{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install python_speech_features # Install PSF specifically on python3.\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import h5py\n",
    "from python_speech_features import mfcc, fbank\n",
    "import matplotlib.pyplot as plt\n",
    "import tracemalloc\n",
    "from SerialTriggerDecoder import SerialTriggerDecoder\n",
    "from scipy import signal\n",
    "# Import fft\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "\n",
    "tracemalloc.start() # Enable memory profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find files, and list structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OS walk through the directory to find the files\n",
    "#root_dir = '//uni.au.dk/dfs/Tech_EarEEG/Students/Msc2022_BCM_AkselStark'\n",
    "root_dir = 'bcm_behaviour_data_multi_subject'\n",
    "data = [] # Empty list to store all hdf5 files in the directory\n",
    "\n",
    "for subdir, dirs, files in sorted(os.walk(root_dir)):\n",
    "    for file in files:\n",
    "        if \"hdf5\" in file:\n",
    "            print(\"\\n\\n\\n\")\n",
    "            # Load the hdf5 file, and append to the list\n",
    "            print(file)\n",
    "            \n",
    "            data.append(h5py.File(os.path.join(subdir, file), 'r'))\n",
    "            \n",
    "            print(f'{subdir}/{file}') # Print the filename\n",
    "            keylist = list(data[0].keys())\n",
    "            print( keylist) # Print the keys of the hdf5 file\n",
    "            \n",
    "            \n",
    "#data = data[:3] # Create subset of the files, to create training and validation set\n",
    "del data[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in enumerate(data):\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(f'Index of the hdf5 file: {i}') # Print the index of the hdf5 file\n",
    "    for key in keylist:\n",
    "        print(key)\n",
    "        try: # Try to print the keys. If it fails, print the data\n",
    "            print(f\"    {list(data[i][key].keys())}\")\n",
    "        except:\n",
    "            print(\"    No subkeys\")\n",
    "            print(f\"    {np.array(data[i][key])}\")\n",
    "            s = data[i][key]\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Memory usage: {tracemalloc.get_traced_memory()[0]/1000000} MB\\n')\n",
    "data_bcm = []\n",
    "labels_bcm = []\n",
    "for file in data:\n",
    "    print(f\"data    {file}\")\n",
    "    data_full = np.array(file['DAQ970A']['data'])\n",
    "    data_bcm.append(data_full[:,0])\n",
    "    data_bcm.append(data_full[:,1])\n",
    "    print(f'Memory usage: {tracemalloc.get_traced_memory()[0]/1000000} MB\\n')\n",
    "\n",
    "    print(f\"Labels    {file}\")\n",
    "    labels_bcm.append(file['DAQ970A']['data'][:,3])\n",
    "    print(f'Memory usage: {tracemalloc.get_traced_memory()[0]/1000000} MB\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_decoded = -500000\n",
    "label_index_list = [] # List of the indices of the labels\n",
    "for i, j in enumerate(np.rint(labels_bcm[0])):\n",
    "    \n",
    "    if int(j) and (i > last_decoded+50000*8):\n",
    "        #print(manchester_decode(np.rint(labels_bcm[0][i-900:i+100000][0::2480])))\n",
    "        print(f\"i: {i}\")\n",
    "        print(f\"Time: {i/50000} s\")\n",
    "        last_decoded = i\n",
    "        \n",
    "        label_index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_labels = [] # A list of labels for the indexes in label_index_list\n",
    "\n",
    "for i in range(6):\n",
    "    index_labels.extend([0,0,0,1,1,1,2,2,2,-1])\n",
    "\n",
    "for i in range(18): index_labels.append(3)\n",
    "index_labels.append(-1)\n",
    "\n",
    "for i in range(18): index_labels.append(4)\n",
    "index_labels.append(-1)\n",
    "\n",
    "# New list with negative values removed list conprehension\n",
    "index_labels_new = [x for x in index_labels if x != -1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pcolormesh of index_labels where the labels are > 0\n",
    "fig = plt.figure(figsize=(30, 5))\n",
    "plt.pcolormesh(np.array(index_labels_new).reshape(1,-1),shading='auto',cmap='tab10')\n",
    "\n",
    "# Add legend outside of the plot\n",
    "plt.legend(['0', '1', '2', '3', '4'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sections to 5 lists corresponding to the 5 different labels/classes\n",
    "''' \n",
    "Classes:\n",
    "    Breathing: 0\n",
    "    Snoring: 1\n",
    "    Hold_breath: 2\n",
    "    Chewing: 3\n",
    "    Talking: 4\n",
    "'''\n",
    "fs = 50000\n",
    "nested_class_list = [[],[],[],[],[]]\n",
    "\n",
    "\n",
    "for datastream in data_bcm: # Loop through the data \n",
    "    for i, j in enumerate(label_index_list):\n",
    "        if index_labels[i]>=0:\n",
    "            nested_class_list[index_labels[i]].append(datastream[j:j+fs*10]) # Append "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "class_label_list = ['Breathing', 'Snoring', 'Hold_breath', 'Chewing', 'Talking']\n",
    "\n",
    "# Concatenate the arrays, calc mfccs and save them to files\n",
    "for i, j in enumerate(nested_class_list):\n",
    "    stacked_array = np.hstack(j)\n",
    "    \n",
    "    # Plot the stacked array\n",
    "    '''fig = plt.figure(figsize=(30, 5))\n",
    "    plt.plot(stacked_array, label=f'Data for label {i}')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.grid(which = 'minor')\n",
    "    plt.show()'''\n",
    "    \n",
    "    # Create and save mfccs\n",
    "    data_mfcc = mfcc(stacked_array, samplerate = fs, nfft = 1600, winlen=0.032, winstep=0.032, numcep=16) # Sample rate is important when using mel scale\n",
    "    \n",
    "    #plot_mfcc(data_mfcc)\n",
    "    \n",
    "    np.save(f'data/bcm_alt_3/train/{i}.npy', data_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
